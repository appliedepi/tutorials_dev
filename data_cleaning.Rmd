---
title: "Data cleaning"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
description: >
  Learn how to get started with R and RStudio, and how to import a dataset
---

<!-- Add JavaScript code for making the exercise code larger -->
<script language="JavaScript" src="js/exercise-font-size.js"></script>

```{r setup, include=FALSE}
# load packages ----------------------------------------------------------------
library(learnr)
library(gradethis)
library(tidyverse)
library(here)
library(janitor)
library(rio)
library(basket) # not sure if we need this
library(etude) # helper functions for gradethis

# set options for exercises and checking ---------------------------------------
gradethis_setup()

learnr::tutorial_options(exercise.timelimit = 60) 
  #exercise.checker = gradethis::grade_learnr) 
    # alternatively, submitr::null_code_checker


# event recorder ---------------------------------------------------------------
# see https://github.com/dtkaplan/submitr/blob/master/R/make_a_recorder.R
tutorial_options(exercise.eval = FALSE)  # pre-evaluate exercises

vfun <- submitr::make_basic_validator(NULL, "hello") #basket::check_valid

new_recorder <- function(tutorial_id, tutorial_version, user_id, event, data) {
    cat(
      tutorial_id, 
      " (v", tutorial_version, "); ",
      format(Sys.time(), "%Y-%M%-%D %H:%M:%S %Z"), "; ",
      user_id, "; ",
      event, "; ",
      data$label, "; ",
      data$answers, "; ",
      data$code, "; ",
      data$correct, "\n", sep = "",
      
      file = here::here("event_records", "learnr_basics.txt"),
      append = TRUE)
}

options(tutorial.event_recorder = new_recorder)


# hide non-exercise code chunks ------------------------------------------------
knitr::opts_chunk$set(echo = FALSE)


# data prep --------------------------------------------------------------------
linelist_raw <- rio::import(here::here("data", "linelist_raw.xlsx"))
linelist <- rio::import(here::here("data", "linelist_cleaned.rds"))
malaria_counts <- rio::import(here::here("data", "malaria_facility_count_data.rds"))

#Incorrectly assign class so we can clean later
linelist_raw$age <- as.character(linelist_raw$age)
linelist_raw$`date onset` <- as.character(linelist_raw$`date onset`)

```


```{r}
submitr::login_controls() # show login and password with "Submit" button.
```


```{r context = "server", echo = FALSE}
# see https://rdrr.io/github/dtkaplan/submitr/f/vignettes/using.Rmd
options(tutorial.storage = "none")
vfun <- submitr::make_basic_validator(NULL, "hello")       #basket::check_valid
storage_actions <- submitr::record_local("./minimal_submissions.csv")
submitr::shiny_logic(input, output, session, vfun,
                     storage_actions)
```




## Introduction to R for Applied Epidemiology and Public Health
### Data cleaning and core functions

```{r appliedepi-banner, fig.margin = TRUE, echo = FALSE, fig.width = 3, out.width = "100%", fig.cap = ""}
knitr::include_graphics("images/moz-banner.png")
```


### Welcome

Welcome to the course "Introduction to R for applied epidemiologists", offered for free by [Applied Epi](www.appliedepi.org) - a non-profit organisation that offers open-source tools, training, and support to frontline public health practitioners.

This interactive tutorial focuses on **cleaning of datasets often encountered by applied epidemiologists and public health practitioners**, such as outbreak linelists, surveillance, and laboratory data.  


#### Target Audience  

This course is designed with the following objectives: 

* To be friendly to people who have never used a programming language before
* To teach R emphasizing examples, datasets, and challenges commonly faced by applied epidemiologists
* To be modular - so that you can skip to section most relevant to you

If this is your first introduction to R programming, please consider first completing our [R Setup and Data Import tutorial], which introduces R, RStudio, R projects, R code syntax, and explains how to import a dataset into R.  



#### Other languages
This course is available...


#### Offline / Online

You can access this tutorial offline by downloading our R package ... 
If viewing offline, you can view the videos by doing ...



#### Learning goals

In this tutorial you will learn and practice:  

* Using the pipe operator (`%>%`) to pass the dataset from one cleaning function to another
* The core **tidyverse** R functions used to reduce, clean, and modify data frames  
* How to manipulate dates in order to clean and translate between units of time (days/months/years) with the **lubridate** package
* The use of descriptive analysis and summary statistics with the **janitor** package in order to summarise your data



This tutorial adapts the [Data cleaning and core functions](https://epirhandbook.com/en/cleaning-data-and-core-functions.html) section of our free [ Epidemiologist R Handbook](https://epirhandbook.com/en/), which is available for use offline as well. 


#### Data consent

We continually improve these tutorials by collecting your entries and submitted answers to the quiz questions. By continuing, you consent to this collection and use.

To continue anonymously... do XYZ.



#### Who made this course  

This course is designed by epidemiologists with decades of ground-level experience in outbreak response and local public health work. 


```{r appliedepi-hexes, fig.margin = TRUE, echo = FALSE, fig.width = 3, out.width = "50%", fig.cap = ""}
knitr::include_graphics("images/hex-sidebyside.png")
```


## Data used and directory structure

In this tutorial we will use the following datasets. Please take a few minutes to review the structure and content of each dataset before continuing.

Use the arrows on the right to scroll through hidden columns. Note that these are "raw" (messy) datasets that mimic problems commonly found in real-life epidemiological datasets.  


### **A "linelist" of cases in a fictional (not real) Ebola outbreak***

A "linelist" is a term used in applied epidemiology to refer to a table that contains key information about each case or suspect case in an outbreak. Each row represents one case, and the columns contain variables such as age, sex, date of symptom onset, outcomes, etc.

This dataset contains `r nrow(linelist_raw)` rows and `r ncol(linelist_raw)` columns. Below are the first 5 rows:  

```{r}
head(linelist_raw)
```

Click to [download the **raw** dataset](https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_raw.xlsx) for your own practice.

Click to [download the **clean** dataset as an **.rds file**](https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/linelist_cleaned.rds) for your own practice. A *.rds file* is an R-specific file type that preserves column classes. This ensures you will have only minimal cleaning to do after importing the data into R.

### **Aggregated data from malaria surveillance in a fictional country**  

Aggregated data in epidemiology usually means a table of counts for each facility, or district, etc. Sometimes, the counts can also be per day, week, or month.  

In this fictional dataset, each facility reported *daily* case counts of rapid-test (RDT)-confirmed malaria. Thus, each row represents the number of cases for a specific facility on a specific day.  

This dataset contains `r nrow(malaria_counts)` rows and `r ncol(malaria_counts)` columns. Below are the first 5 rows:  

```{r}
head(malaria_counts)
```


Click to [download the **clean** malaria counts dataset as an **.rds file**](https://github.com/appliedepi/epirhandbook_eng/raw/master/data/malaria_facility_count_data.rds) for your own practice. A *.rds file* is an R-specific file type that preserves column classes. This ensures you will have only minimal cleaning to do after importing the data into R.


### Directory structure

Photo or GIF of directory structure

### Accessing example data
Here is how to access the example data

### Tidy Data

We highly recommend doing our tutorial on Tidy Data in Applied Epidemiology. Collecting, formatting, and preparing your dataset *before* importing it into R is a critical step!
LINK
VIDEO TEASER




## Install and Load R packages {#packages}

To use basic functions with public health data, the tidyverse metapackage is very useful. Tidyverse loads the dplyr, ggplot2, and other packages that are useful in epi data analysis. 

We've preloaded the below packages for now. Installation and loading of these packages is described on the EpiRHandbook [_Suggested Packages_](https://epirhandbook.com/en/suggested-packages-1.html) page. 


In this assignment we'll work with X R packages, let's load them!

```{r load-package, exercise = TRUE}
pacman::p_load(___)
```

```{r load-package-hint}
pacman::p_load(rio, here, janitor, tidyverse)

```

```{r load-package-check}
grade_this_code("You are correct, the packages you need for this lesson are now loaded!")
```

```{r eval=FALSE}
pacman::p_load(learnr, here, rio, janitor, tidyverse)
```

### Recommended R packages for public health

See this Epi R Handbook LINK for our recommended packages.









## Import data {#import} 
https://www.epirhandbook.com/en/import-and-export.html
Import that data and save it as "raw" file

To import data from a sub-folder, the `import()` command should be modified so that it correctly tells R where to search for this file. This is done using the here() function. 

```{r import-demo-subfolder, echo=T, eval=F}
linelist_raw <- import(here("data", "linelist_raw.xlsx"))   # import data and save as named object
```


## Begin pipe chain
What is a pipe chain?
A pipe chain refers to the use of the "pipe" operator `%>%` to chain together operations (such as cleaning, reordering and manipulating) for altering a dataset. 

This allows us to carry out several different alterations of the dataframe in a single operation. It can be helpful to think of the pipe operator `%>%` as telling the computer "and then" between your operational commands. The order of this pipeline is important as operations occur sequentially, and so improperly ordered arguments may fail or (potentially more dangerously!) give incorrect values or unwanted outcomes.

Can you connect the following commands from the **janitor** package (`clean_names`, `select(contains("date_"))` and `names()` to clean the dataset `linelist_raw` and display the names of any columns that contain "_date"?

```{r pipe_linelist, exercise = TRUE}
linelist_raw %>%
  
```

```{r pipe_linelist-hint}
linelist_raw %>%
  clean_names() %>%

```

```{r pipe_linelist-check}
grade_result(
  pass_if(~ identical(.result, linelist_raw %>%
    clean_names() %>%
    select(contains("date_")) %>%
    names() ), "You have correctly linked the functions in order and displayed the names of the cleaned dataset, good work!")
)
```


```{r eval = FALSE}
linelist_raw %>%                              #Define the dataset, and then
         clean_names() %>%                    #clean the dataset columns, and then
         select(contains("date_")) %>%        #Select columns where their name contains "date_", and then
         names()                              #Display the column names

```


## Pipe chain
If the order of cleaning and selecting columns had not been correct, then you would have missed the column "date_onset" as in the raw linelist it was called "date onset". 

This was a very simple example giving you a first taste of pipe operators and cleaning functions, as we progress through the chapter you will gain more familiarity with the functions available and how to use them in increasingly complex examples.

## Clean columns

In R, column names are the header, or top, value of a column and are used as the default value in figures. In other statistical software (such as SAS and STATA) "labels"  co-exist as longer printed versions of shorter column names, and while R can do this, it is not emphasized and for plotting and printing "friendly" column names, we generally adjust their display in the code to create the figure or tables.

As we call column names often, it is helpful to have a "clean" syntax. We suggest that they are:

*   Short
*   No spaces (replace with underscores)
*   No unusual characters (&, #, <, >, ...)
*   Similar style nomenclature (e.g. all date columns named like "**date_**"onset, "**date_**"report, "**date_**"death, ...)

These are often not what real, raw, data and linelists look like, luckily R has a set of very handy and easy to use tools to clean and standardize column names.

For example, if we look at the example linelist using the `names()` function:
```{r, echo = T, eval = T}
names(linelist_raw)
```
We can see that there are numerous violations of this clean syntax. We have names with spaces (infection date), different naming patterns for dates (date onset vs infection date) and there must have been a merged header across the last two columns (as the second last column i called "merged_header" and the last "...28" indicating it was assigned a placeholder name (it is the 28th column)). 

Manually changing these column names to the preferred clean syntax would be time consuming, error prone and would need to be repeated everytime new versions of the linelist became available. Luckily, R has some helpful functions to make this process much faster and reproducible.

### Clean names

The first function we will explore in detail is the `clean_names()` function from the **janitor** package. This function does a lot of the hard work of cleaning column names for us. It does this through:

* Converting names to consist of only underscores, numbers and letters
* Accented characters are transliterated to ASCII (e.g. german o with umlaut becomes “o”, spanish “enye” becomes “n”)
* Capitalization preference for the new column names can be specified using the case = argument
* You can specify specific name replacements by providing a vector to the replace = argument (e.g. replace = c(onset = "date_of_onset"))

Here we can see the differences in the column names of the cleaned and uncleaned dataset.

```{r, echo = T, eval = T}
linelist_raw %>%                              #Define the dataset, and then
  names()                                     #Display the column names

linelist_raw %>%                              #Define the dataset, and then
         clean_names() %>%                    #clean the dataset columns, and then
         names()                              #Display the column names

```

You can see that this has done a lot of the work for us, replacing spaces with "_", and ensuring there are no unusual characters. However, if we want to standardize the entire dataset to the "clean syntax" described previously, we will have to include additional cleaning stages.

For example, if we wanted to use a similar style nomenclature such as "**date_**", then we would have to carry out additional steps to the columns "infection_date", "hosp_date", "date_of_outcome".

This manual name cleaning can be done through the function `rename()` from the **dplyr** package as part of a pipe chain. Here the function follows the syntax `NEW = OLD`. So to clean the linelist, rename the columns previously mentioned and then display the names, we would do the following:

```{r, echo = T, eval = T}
linelist_raw %>%
  clean_names() %>%
         #New name         #Old names
  rename(date_infection = infection_date,
         date_hospitalisation = hosp_date,
         date_outcome = date_of_outcome) %>%
  names()

```

As you can see, the column names have changed. You can also do this by column position, though this is less encouraged as column positions can easily change between datasets and versions. Here we are updating the names of column 1 and 2 to "id" and "gen"

```{r, echo = T, eval = T}
linelist_raw %>%
  clean_names() %>%
         #New name #Old names
  rename(id = 1,
         gen = 2) %>%
  names()
```

### Select columns

Another way of re-naming columns is through the `select()` function. This function subsets your dataset, removing unwanted columns, and allowing you to rename the columns you have kept.

```{r, echo = T, eval = T}

linelist_raw %>%
  select(#New name #Old name
    date_infection = 'infection date',
    date_hospitalisation = 'hosp date')

```

As you can see, this has subset to the columns with the original names of `'infection date'` and `'hosp date'` and renamed them. Note, because of the spaces in the names of the dataset we need to put the column name within ' ' as R does not like spaces in column names.

`select()` can be used without renaming in order to subset a dataset to the columns you are interested in.

```{r, echo = T, eval = F}
linelist_raw %>%
  select(case_id, generation, gender)
```


Using what we have learned, can you `clean()`, `rename()`, `select()` and `head()` to recreate the output below?

```{r}
  linelist_raw %>%                                        #Define the dataset, and then
         clean_names() %>%                              #clean the dataset columns, and then
                #New name   Old name
         rename(date_infection = infection_date,
                date_outcome = date_of_outcome) %>%     #rename the select columns, and then
         select(case_id, date_infection, date_outcome) %>%
         head()
```

```{r clean_rename_select, exercise = TRUE}

```

```{r clean_rename_select-hint}
Remember the order of your pipe chain is important.
```

```{r clean_rename_select-check}
grade_result(
  pass_if(~ identical(.result, linelist_raw %>%
         clean_names() %>%
         rename(date_infection = infection_date,
                date_outcome = date_of_outcome) %>%
         select(case_id, date_infection, date_outcome) %>%
         head()), "Excellent, you have cleaned the dataset and subset to the columns you want")
)
```

```{r eval = FALSE}
linelist_raw %>%                                        #Define the dataset, and then
         clean_names() %>%                              #clean the dataset columns, and then
                #New name   Old name
         rename(date_infection = infection_date,
                date_outcome = date_of_outcome) %>%     #rename the select columns, and then
         select(case_id, date_infection, date_outcome) %>%
         head()
```

This gives you an insight into how to clean and subset a dataset, however when you have a large dataset manually specifiying columns can be cumbersome. Sometimes you want to extract columns with a specific prefix/suffix, or when they contain a certain word. 

Rather than manually typing these out, and especially if we have a cleaned dataset adhering to the "clean style" syntax specified previously, we can use "tidyselect" helper functions

## Tidyselect helper functions

Tidyselect helper functions are functions that work within **dplyr** functions such as `select()`, `across()` or `summarise()`. These offer convenient shortcuts for selecting subsets of columns that match specified criteria:

* `everything()` - all othecolumns not mentioned
* `last_col()` - the last column
* `where()` - applies a function to all columns and selects those which are true
  * example: `select(where(is.numeric))`
  * This would select all columns where the class is numeric
* `contains()` - columns containing a character string
  * example: `select(contains("time"))`
* `starts_with()` - matches to a specified prefix
  * example: `select(starts_with("date_"))`
* `ends_with()` - matches to a specified suffix
  * example: `select(ends_with("_post"))`
* `matches()` - to apply a regulaexpression (regex)
  * example: `select(matches("[pt]al))`
  * Regulaexpression (regex) refers to a sequence of characters that specifies a search pattern in text. If you are unfamiliawith regex, then there some aspects may seem non-intuitive, foa good introduction to the use of regex please see https://cran.r-project.org/web/packages/stringr/vignettes/regular-expressions.html.
* `num_range()` - a numerical range
  * example: `select(num_range("week", 1:5))`
* `any_of()` - matches if the column exists, but returns no erroif it is not found
  * example: `select(any_of(date_onset, date_death, cardiac_arrest))`
  
In addition to these we can use normal operators such as:

* `c()` - to list several columns
  * example: `select(c(date_onset, hosp_date, gender))`
* `:` - to select consecutive columns
  * example: `select(1:5)`
* `!` - fothe opposite
  * example: `select(!c(date_onset, hosp_date, gender))`
  * This would _not_ select date_onset, hosp_date, gender
* `&` - AND
  * example: `select(matches("date" & "outcome"))`
* `|` - OR
  * example: `select(matches("date" | "outcome"))`

Select can also be used to remove columns, rather than keep, by putting the minus symbol "-" in front of the column name

```{r, eval = T, echo = T}
linelist %>%
  select(-c(date_onset, fever:vomit)) %>% #This will remove date_onset and all columns from fever to vomit
  names()
```

You can also remove a column using base R syntax, by defining it as NULL. For example:
```{r, eval = F, echo = T}
linelist$date_onset <- NULL #Deletes column with base R syntax
```

### Quiz
```{r quiz1}
quiz(
  question("Which of these column names follows a clean syntax?",
    answer("date hospitalisation"),
    answer("date_of_patient_hospitalisation"),
    answer("date@hospitalisation"),
    answer("date_hosp", correct = TRUE)
  ),
  question("Which of these functions can be used to rename columns?",
           answer("rename()", correct = TRUE),
           answer("clean_names()", correct = TRUE),
           answer("head()"),
           answer("select()", correct = TRUE)
           ),
  question("Why is it useful to follow a similar style nomenclature (all date columns starting *date_*) for column names?",
    answer("It looks good when you output tables and figures"),
    answer("It helps us find relevant columns and makes omissions/errors less likely", correct = TRUE),
    answer("R is very inflexible and only allows certain combinations of words"),
    answer("It allows us to sort the dataset by alphabetical order")
  ),
  question("In which order would you place these functions in order to output only the names of the columns 'date_onset' and 'outcome' from linelist_raw",
           answer("clean_names(), select(date_onset, outcome), names()", correct = TRUE),
           answer("select(date_onset, outcome), clean_names(), names()"),
           answer("clean_names(), select(-c(date_onset, outcome)), names()"),
           answer("clean_names(), select(date_onset, outcome), head()")
           )
   
)
```

Can you write a pipe chain that drops the columns from `lon` to `source` from linelist_raw?

```{r drop_lon_to_source, exercise = TRUE}

```

```{r drop_lon_to_source-hint}
It is good practice to clean your column names, but it is not necessary to in this example. 

Remember, you do not need to specifiy each column name individually that you want to drop between two columns
```

```{r drop_lon_to_source-check}
grade_result(
  pass_if(~ identical(.result, linelist_raw %>%
         select(-c(lon:source)) ), "Good work, ':' is a useful tool for referencing several concurrent columns.")
)
```

```{r eval = FALSE}
linelist_raw %>%                    #Define the dataset, and then
         select(-c(lon:source))     #Remove all columns between lon and source
```

We need to put all columns with a "date" in them into the same nomenclature (*date_*) and then subset linelist_raw to contain these and all symptom columns.
How would you do this using only `clean_names()` and `select()`?

```{r date_symptom_subset, exercise = TRUE}

```

```{r date_symptom_subset-hint}
You will have to combine renaming, a tidyselect helper function and a normal operator within select() to efficiently clean and subset
```

```{r date_symptom_subset-check}
grade_result(
  pass_if(~ identical(.result, linelist_raw %>%
  clean_names() %>%
  select(date_infection = infection_date,
         date_hospitalisation = hosp_date,
         starts_with("date_"),
         fever:vomit) ), "Combining multiple operations within a select function allows us to efficiently clean, rename and subset data. Nice one.")
)
```

```{r eval = FALSE}
linelist_raw %>%
  clean_names() %>%
  select(date_infection = infection_date,
         date_hospitalisation = hosp_date,
         starts_with("date_"),
         fever:vomit)
```

## New columns

Creating new columns and transforming existing ones is easily done in R, where we recommend using the **dplyr** package function `mutate()` which uses the syntax `NEW = VALUE/TRANSFORMATION`.

For example, this would create a new column called `new_col` where each row has the value of 10.

```{r eval = F, echo = T}
linelist %>%
  mutate(new_col = 10)
```

You can also reference pre-existing columns to perform calculations. For example, to calculate the Body Mass Index (BMI) we can use the formula BMI = kg/m^2 using the column `ht_cm` and `wt_kg` through:
```{r eval = T, echo = T}
linelist %>%
  mutate(bmi = wt_kg/(ht_cm/100)^2) %>%
  select(wt_kg, ht_cm, bmi) %>%          #This selects just the wt_kg, ht_cm and bmi columns
  head()                                 #This displays the top 6 rows to check
```

In base R this would be carried out with
```{r, echo = T, eval = F}
linelist$bmi = linelist$wt_kg / (linelist$ht_cm / 100) ^ 2)
```

We can also create multiple new columns at once, which are separated with a comma and should begin on a new line
```{r eval = T, echo = T}
linelist %>%                       
  mutate(
    new_var_dup    = case_id,             # new column = duplicate/copy another existing column
    new_var_static = 7,                   # new column = all values the same
    new_var_static = new_var_static + 5,  # you can overwrite a column, and it can be a calculation using other variables
    new_var_paste  = stringr::str_glue("{hospital} on ({date_hospitalisation})") # new column = pasting together values from other columns
    ) %>% 
  select(case_id, hospital, date_hospitalisation, contains("new")) %>%
  head()

```


```{r quiz2}
quiz(
  question("Which function can be used to create new columns?",
    answer("select()"),
    answer("mutate()", correct = TRUE),
    answer("rename()"),
    answer("clean_names()")
  ))
```

Can you take what you have learned in the previous chapters and create a new column called `age_months` from `age`, and then subset to only include `age`, `age_months` and `gender`? Note, you should ensure that all values in age are the same unit (specified in `age_unit`), and convert according to this.

```{r date_mutate, exercise = TRUE}

```

```{r date_mutate-hint}
You can use ifelse() to carry out different operations based on another value, this is a vectorised version of the if statement, and so will run through each row of a column and return an answer
ifelse(age_unit == "years",   #The condition, if the value in the column age_unit DOES equal years then the function will return...
       age * 12,              #this value, and if the value in column age_unit DOES NOT equal years, then the function will return...
       age                    #the value in age without manipulation
)
```

```{r date_mutate-check}
grade_result(
  pass_if(~ identical(.result, linelist %>%
  mutate(age_months = ifelse(age_unit == "years", age * 12, age)) %>%
  select(age, age_months, gender)), "Great, you have created a new column based and learned about the ifelse() function.")
)

```

## Converting column class

Columns contain values that are dates, numbers or logical values (TRUE/FALSE) and will only behave if correctly classified. Trying to sum "2" and "1" of class character will return an error, and summing 2 and 1 of class numeric will return 3.

The class of a column is displayed when we use `skim()` and individually we can check the value of columns with `class()`. For instance,

```{r, echo = T, eval = T}
class(linelist_raw$age)
```

we can see that this column has been incorrectly assigned as "character". Can you reassign the value of this column to numeric using `as.numeric()`?

```{r change_class, exercise = T}

```

```{r change_class-check}
grade_result(
  pass_if(~ identical(.result, linelist %>%
  mutate(age = as.numeric(age))), "Good work.")
)
```

Using the same syntax you can convert columns to character with `as.character()` or to logical operators, `as.logical()` or to a factor with `as.factor()` with base R, or `as_factor` from the package **forcats**.

Converting dates is slightly trickier, and it requires careful attention to the format (e.g. "Month/Day/Year" or "Day/Month/Year"). After converting to the class Date, check your data to confirm each value was converted correctly.

## Grouping data

Often your data will be grouped, and so functions such as `mutate()` will behave differently than if the data is not grouped. Additionally, summarising functions such as `mean()`, `min()`, `max()` will calculate by group and not by all the rows.

```{r, eval = T, echo = T}
# age normalized to mean of ALL rows
linelist %>% 
    summarise(mean_age = mean(age, na.rm = T))

# age normalized to mean of hospital group
linelist %>% 
    group_by(hospital) %>% 
    summarise(mean_age = mean(age, na.rm = T))
```

## Cumulative math

In your datasets, you may want to take cumulative sum/mean/min/max etc values across all the rows in the dataframe. For example, calculating the cumulative sum of cases across an outbreak or per day can give us an idea of how the infection is progressing. To calculate the cumulative sum across the entire outbreak, we would do the following:

```{r}

linelist %>%                                 #Begin with the case linelist, and then
  count(date_onset) %>%                      #count of rows per day, as column 'n' by default, and then
  mutate(cumulative_cases = cumsum(n)) %>%   #new column, of the cumulative sum at each row, and then
  head(10)                                   #display the first 10 rows

```

Can you use what you have learned in order to produce a cumulative sum (in a column called cumulative_cases) of the epidemic by healthcare setting from linelist?

```{r cumulative_sum, exercise = TRUE}
linelist %>% 

```

```{r cumulative_sum-hint}
Remember to use group_by() 

```

```{r cumulative_sum-check}
grade_result(
  pass_if(~ identical(.result, linelist %>% group_by(hospital) %>%
    count(date_onset) %>%
    mutate(cumulative_cases = cumsum(n))), "Great, it's hard to see because we have 1629 rows, but you have correctly grouped and cumulatively summed by hospital!")
)
```


## across()

The function across() allows us to apply a function to everything specified within it. Columns are specified using the `.cols =` function, either individually, or with "tidyselect" helper functions. The function to apply to these columns is then specified with `.fns = ` (note the function is specified _without_ parentheses "()").

```{r, eval = T, echo = T}
linelist %>%
  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))
```

```{r quiz3}
quiz(
  question("What will this pipe chain do?",
    answer("Check the columns temp, ht_cm and wt_kg to see if they are the character class and return a TRUE/FALSE"),
    answer("Check the columns temp, ht_cm and wt_kg to see if they are the character class"),
    answer("Convert the columns temp, ht_cm and wt_kg to character class and make new columns"),
    answer("Convert the columns temp, ht_cm and wt_kg to character class and update existing columns", correct = TRUE)
  ))
```

Can you update the above function using "tidyselect" helper functions to convert any columns that contain "date" to character?

```{r tidyselect_date_character, exercise = T}

```

```{r tidyselect_date_character-check}
grade_result(
  pass_if(~ identical(.result, linelist %>%
  mutate(across(.cols = contains("date"), .fns = as.character))), "Great work")
)
```

## Coalesce

This **dplyr** function allows us to "fill in" missing values with the first available value in an order you specify. For example, you have two vectors, one containing the patient’s village of detection and another containing the patient’s village of residence. You can use coalesce to pick the first non-missing value for each index:

```{r, eval = T, echo = T}
village_detection <- c("a", "b", NA,  NA)
village_residence <- c("a", "c", "a", "d")

village <- coalesce(village_detection, village_residence)
village    # print
```

This works the same way for a dataset

```{r, eval = T, echo = T}
linelist %>% 
  transmute(first_date = coalesce(date_infection, date_onset),#transmute() is the same as mutate(), except it drops everything not specified in the brackets
            date_infection, 
            date_onset) %>% 
  head()
```


## Deduplication

The package **dplyr** has the function  `distinct()` which removes duplicated rows in the dataset, by default it considers all columns though this can be adjusted. Here we will ensure that no rows are 100% duplicates of other rows (evaluated across all columns) in the dataset `linelist_raw`. We are comparing the number of rows in the original and de-duplicated 

```{r}
nrow(linelist_raw)

linelist_raw %>%
  distinct() %>%
  nrow()
```
As you can see the linelist goes from 6611 rows to 6609 These omitted rows would have been 100% duplicates of other rows.

## Quiz

Now we are going to run through everything we have learned so far in order to convert `linelist_raw` into `linelist`, this will require several steps.

* Cleaning names, both automatically and manually renaming date columns to the clean syntax
* Removing the columns "row_num", "merged_heder" and "x28"
* De-duplicating
* Adding in the new column "bmi"
* Converting all date columns to the date class, generation and age to numeric class

```{r linelist_raw_to_linelist, exercise = TRUE}


```

```{r linelist_raw_to_linelist-hint}
You have already done each of these steps individually (and some together), this is a case of remembering how to use rename(), select(), mutate() and a few other functions.

```

```{r linelist_raw_to_linelist-check}
grade_result(
  pass_if(~ identical(.result, linelist_raw %>%
  janitor::clean_names() %>% 
  rename(date_infection       = infection_date,
         date_hospitalisation = hosp_date,
         date_outcome         = date_of_outcome) %>% 
  select(-c(row_num, merged_header, x28)) %>% 
  distinct() %>% 
  mutate(bmi = wt_kg / (ht_cm/100)^2) %>% 
  mutate(across(contains("date"), as.Date), 
         generation = as.numeric(generation),
         age = as.numeric(age)) ), "You have strung together numerous functions in order to create a clean dataset, you are well on your way to becoming a data cleaning expert.")
)
```

## Re-code values

You will occasionally have to re-code values, this can be due to a number of reasons

* To edit one specific value (e.g. one date in the wrong format)
* To reconcile values not spelled the same
* To create a new column of categorical values
* To create a new column of numeric categories (e.g. age categories)

To change values manually we can use the `recode()` function within `mutate()`. For instance, to fix a date that has been incorrectly included we use the following:
```{r, echo = F, eval = F}
linelist %>%                             #Old value     #New value
  mutate(date_onset = recode(date_onset, "2014-14-15" = "2014-04-15"))
```

Another example of when you would use recode is if you have a column with several different spellings and missing values.

```{r, echo = T, eval = T}
table(linelist_raw$hospital, useNA = "always")  # print table of all unique values, including missing  
```

As you can see, we need to do some manual cleaning in order to correct misspellings. 

```{r, echo = T, eval = T}
linelist_updated <- linelist_raw %>% 
  mutate(hospital = recode(hospital,
                     # for reference: OLD = NEW
                      "Mitylira Hopital"  = "Military Hospital",
                      "Mitylira Hospital" = "Military Hospital",
                      "Military Hopital"  = "Military Hospital",
                      "Port Hopital"      = "Port Hospital",
                      "Central Hopital"   = "Central Hospital",
                      "other"             = "Other",
                      "St. Marks Maternity Hopital (SMMH)" = "St. Mark's Maternity Hospital (SMMH)"
                      ))

table(linelist_updated$hospital, useNA = "always")

```

We can also re-code based on logical cirteria, you can use `replace()` within `mutate()` and use it with logical conditions in order to specify which rows to change using the following general syntax

```{r, eval = F, echo = T}
mutate(col_to_change = replace(col_to_change, criteria for rows, new value))
```

For instance, if you know a row that is identified with a certain id has the wrong value (such as gender), you can correct this using a logical condition. 
```{r, eval = F, echo = T}
linelist %>% 
  mutate(gender = replace(gender, case_id == "2195", "Female"))
```

This will find the row with the `case_id` of "2195" and change the gender to "Female".

Another useful tool for simple logic is `ifelse()`, `if_else()` and `case_when()`. These "if else" commands are simplified versions of an `if` and `else` programming statement with the general syntax of
```{r, eval = F, echo = T}
ifelse(condition, value to return if condition evaluates to TRUE, value to return if condition evaluates to FALSE)
```

Here we are creating a column `source_known` column where the value of a row is "known" if the row's value in column `source` is _not_ missing. If it _is_ missing then it will be set to "unknown"

```{r, eval = F, echo = T}
linelist %>% 
  mutate(source_known = ifelse(!is.na(source), "known", "unknown"))
```

if_else() is a function from **dplyr** that handles dates. Note that if the "true" value is a date, the "false" value must also qualify a date, hence the use of `NA_real_` instead of `NA`.
```{r, eval = F, echo = T}
linelist %>% 
  mutate(date_death = if_else(outcome == "Death", date_outcome, NA_real_))
```

###Quiz
```{r quiz4}
quiz(
  question("Which of these simple logical statements would replace 'Other' with 'Unidentified' in the column 'hospital'?",
    answer("mutate(hospital = ifelse(hospital == 'Other', 'Unidentified', hospital))", correct = TRUE),
    answer("mutate(hospital = ifelse(hospital == 'Unidentified', 'Other', hospital))"),
    answer("mutate(hospital = ifelse(hospital == 'Other', 'Unidentified', 'Identified'))"),
    answer("mutate(hospital = ifelse(Other == 'hospital', 'Unidentified', hospital))")
  ),
  question("What will this pipe chain do?",
    answer(""),
    answer(""),
    answer(""),
    answer("", correct = TRUE)
  ),
  question("What will this pipe chain do?",
    answer(""),
    answer(""),
    answer(""),
    answer("", correct = TRUE)
  ))
```


## Complex logic


## Clean rows

Now that we have worked through how to clean and subset columns, we need to learn how to apply similar approaches to rows. There are several reasons why you would want to clean the rows of your dataset such as to remove duplicate entries, rows that contain NA values in all, or a selection, of columns. These allow us to clean the dataset and produce a final cleaned version that is ready for analysis and figure generation.

### Drop missing values




Touch upon some of these: https://www.epirhandbook.com/en/de-duplication.html
### Filter by logic
### Quiz









## Dates
See Epi R Handbook chapter on working with dates
https://www.epirhandbook.com/en/working-with-dates.html


### Convert to date
#### Character to date
#### Excel to date

### epiweeks
use floor_date() from lubridate
#### ISO weeks

### Quiz


## Pivots
See Epi R Handbook page on Pivoting
https://www.epirhandbook.com/en/pivoting-data.html
### Quiz

## Joins
https://www.epirhandbook.com/en/joining-data.html
### Quiz

## Next steps




